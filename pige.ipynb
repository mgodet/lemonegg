{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c172ed8d-4619-4552-a05b-48b44ad6874a",
   "metadata": {},
   "source": [
    "# AGLAE PIGE data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173e94f-9857-413a-8eed-df27822dc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas ipywidgets xlrd matplotlib openpyxl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c818f66-6b36-4b96-8c2c-1a672c07ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import io\n",
    "import pandas as pd\n",
    "from pandas.api.typing import DataFrameGroupBy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.font_manager\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7dff6-a27e-4e28-89db-3183997c2767",
   "metadata": {},
   "source": [
    "# Upload de fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016399e8-da73-460e-af8f-6ad6354cf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader_report = widgets.FileUpload(description=\"rapport d'analyses\")\n",
    "uploader_pige_sodium = widgets.FileUpload(description=\"données PIGE Na\", accept=\".txt\", style={'description_width': 'initial'})\n",
    "uploader_pixe = widgets.FileUpload(description=\"données PIXE\")\n",
    "has_bore_w = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='A du bore ?',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "display(uploader_report)\n",
    "display(uploader_pige_sodium)\n",
    "\n",
    "# TODO: ajouter autre bouton quand y'a du bore\n",
    "display(has_bore_w)\n",
    "display(uploader_pixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94cd81-5cb3-41c0-9dca-48fabd5120e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uploader_report.value)\n",
    "print(uploader_pige_sodium.value)\n",
    "print(uploader_pixe.value)\n",
    "\n",
    "# l'index des trois tableaux sera le nom du fichier (sans extension)\n",
    "report = pd.read_excel(io.BytesIO(uploader_report.value[0].content), index_col=0)\n",
    "pige_table = pd.read_csv(io.BytesIO(uploader_pige_sodium.value[0].content), sep=\"\\t\", index_col=0)\n",
    "# on enleve \"g7\" pour avoir le meme index dans tous les tableaux pour facilement faire des jointures\n",
    "pige_table.index = pige_table.index.str.replace('.g70', '', regex=False)\n",
    "pige_table.index = pige_table.index.str.replace('.g7', '', regex=False)\n",
    "pixe_table = pd.read_excel(io.BytesIO(uploader_pixe.value[0].content),sheet_name=\"S_Conc. ppm\", header=1, index_col=0)\n",
    "\n",
    "print(pixe_table.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927cd0a-cb18-4bf1-b3dd-9ac8a8da5c48",
   "metadata": {},
   "source": [
    "# On garde les tableaux avec uniquement les standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76525c62-b8dc-452f-aa40-f9d2b27002ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pige_table[\"A/D\"] = pige_table[\"Aire Gaussien\"]/report[\"Dose\"]\n",
    "\n",
    "stds = pd.DataFrame(\n",
    "    {\n",
    "         \"Ref Objet\": [\"BrillA\", \"BrillB\", \"BrillC\", \"BrillD\", \"BG4\", \"BG3\"],\n",
    "         \"Conc theorique\": [143900, 172600, 12000, 10700, 50000, 75000],\n",
    "    }\n",
    ")\n",
    "conc_stds_sans_plomb = stds[stds[\"Ref Objet\"].isin([\"BrillA\",\"BrillB\",\"BrillD\"])]\n",
    "conc_stds_avec_plomb = stds[stds[\"Ref Objet\"].isin([\"BrillC\",\"BG4\",\"BG3\"])]\n",
    "\n",
    "report_stds = report[report[\"Ref Objet\"].isin(stds[\"Ref Objet\"])]\n",
    "\n",
    "# on veut prendre que les standards dans le nom du fichier, on fait ca en appelant contains en mode regex avec tous les standards (séparés par des \"ou\", i.e. la barre '|')\n",
    "pige_stds = pige_table[pige_table.index.str.contains(\"|\".join(stds[\"Ref Objet\"]), regex=True)].copy()\n",
    "\n",
    "# On vérifie que le nombre de standards dans le rapport et dans PIGE est le même\n",
    "print(f\"On a {len(report_stds)} standards dans le rapport d'analyses\")\n",
    "print(f\"On a {len(pige_stds)} standards dans les données PIGE Na\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a5049-a87c-4a72-a358-fa942cfcadce",
   "metadata": {},
   "source": [
    "# Droite de calibration\n",
    "\n",
    "- On trace la droite de calibration PIGE $\\Large c = k \\times \\frac{A}{D}$ avec:\n",
    "  - $c$ la concentration théorique du sodium dans les standards\n",
    "  - $k$ la pente déterminée par méthode des moindres carrés ordinaires.\n",
    "  - $A$ l'aire gaussienne\n",
    "  - $D$ la dose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad3fc3-6a22-4daa-9b20-c5a2ee58015d",
   "metadata": {},
   "source": [
    "On définit d'abord la fonction CALIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc97e55-1080-4391-9030-9c2a9369b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui va afficher les courbes de calibration et son fit linéaire par méthode des moindres carrés ordinaires\n",
    "def calib(titre, ads, conc, axe):\n",
    "    axe.set_title(titre)\n",
    "    axe.set_xlabel(\"Aire / Dose (u.a.)\")\n",
    "    axe.set_ylabel(\"Concentration théorique (ppm)\")\n",
    "    axe.grid(True)\n",
    "    colors = [\"blue\", \"red\"]\n",
    "    coefs = []\n",
    "    align = [\"bottom\", \"top\"]\n",
    "    \n",
    "    # On affiche toutes les droites de calibration\n",
    "    for i, df in enumerate(ads):\n",
    "        # il peut y avoir plusieures prises de standards, on les aggrège dans une liste\n",
    "        ad_stds = df.groupby(\"Ref Objet\")[\"A/D\"].agg(list)\n",
    "        \n",
    "        # Au lieu de fitter chaque standard séparément,\n",
    "        # on va collecter tous les points (x, y) de ce DataFrame\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "        for std, x_vals in ad_stds.items():\n",
    "            # x est déjà une liste, on passe en array NumPy\n",
    "            x_vals = np.array(x_vals, dtype=float)\n",
    "            \n",
    "            # on ne prend que les valeurs theoriques pour lesquelles on a fait une prise experimentale\n",
    "            subset_conc = conc[conc[\"Ref Objet\"] == std][\"Conc theorique\"]\n",
    "            if subset_conc.empty:\n",
    "                # Cas où la référence std n'existe pas dans conc\n",
    "                print(f\"Attention : std '{std}' pas trouvé dans conc.\")\n",
    "                continue\n",
    "\n",
    "            y_val = subset_conc.iloc[0]\n",
    "            y_vals = np.full_like(x_vals, y_val)\n",
    "            axe.plot(x_vals, y_vals, '.', label=f\"{std} {'init' if i == 0 else 'fin'}\", markersize=12, color=colors[i % len(colors)]) \n",
    "            \n",
    "            # On stocke les points dans nos listes globales\n",
    "            all_x.extend(x_vals)\n",
    "            all_y.extend(y_vals)\n",
    "\n",
    "        #display(titre, \"X\", all_x, \"Y\", all_y)\n",
    "        # Si on a recueilli au moins 2 points pour faire un fit\n",
    "        if len(all_x) > 1:\n",
    "            all_x = np.array(all_x, dtype=float)\n",
    "            all_y = np.array(all_y, dtype=float)\n",
    "\n",
    "            # Régression forcée à l'origine : y = a * x\n",
    "            # => X = all_x.reshape(-1,1), Y = all_y\n",
    "            a_coef, _, _, _ = np.linalg.lstsq(all_x.reshape(-1, 1), all_y, rcond=None)\n",
    "            a = a_coef[0]\n",
    "            coefs.append(a)\n",
    "\n",
    "            # Calcul du y_pred\n",
    "            y_pred = a * all_x\n",
    "\n",
    "            ## Calcul du R² classique\n",
    "            #ss_res = np.sum((all_y - y_pred)**2)\n",
    "            #ss_tot = np.sum((all_y - all_y.mean())**2)\n",
    "            #if ss_tot == 0:\n",
    "             #   r_squared = np.nan\n",
    "            #else:\n",
    "             #   r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "            # Calcul du R² no-intercept (style Excel)\n",
    "            ss_res = np.sum((all_y - y_pred)**2)\n",
    "            ss_tot_no_intercept = np.sum(all_y**2)\n",
    "            r_squared = 1 - ss_res/ss_tot_no_intercept\n",
    "\n",
    "            # Tracé de la droite\n",
    "            x_sorted = np.sort(all_x)\n",
    "            y_pred_sorted = a * x_sorted\n",
    "\n",
    "            axe.plot(\n",
    "                x_sorted, \n",
    "                y_pred_sorted, \n",
    "                linestyle=\"--\",\n",
    "                color=colors[i % len(colors)],\n",
    "                #label=f\"Droite {i}: y={a:.2f}x\\nR²={r_squared:.3f}\"\n",
    "            )\n",
    "\n",
    "            x_min, x_max = np.min(all_x), np.max(all_x)\n",
    "            # Calcul du point \"milieu\" pour y mettre le texte\n",
    "            mid_x = 0.5 * (x_min + x_max) - 0.01\n",
    "            mid_y = a * mid_x\n",
    "        \n",
    "            # Angle de la pente en degrés (pour faire pivoter le texte)\n",
    "            #angle = np.degrees(a) / 1000000\n",
    "            angle = np.degrees(np.arctan(a))\n",
    "            \n",
    "            # Ajout du texte sur la droite\n",
    "            axe.text(\n",
    "                mid_x, mid_y,               # Coordonnées où placer le texte\n",
    "                f\"y = {a:.2f} x\\nR²={r_squared:.4f}\",           # Contenu du texte (équation)\n",
    "                rotation=angle,            # Rotation pour suivre la pente\n",
    "                ha=\"left\", va=align[i % len(align)],  # Alignement horizontal/vertical du texte\n",
    "                rotation_mode=\"anchor\",\n",
    "                transform_rotates_text=True,\n",
    "                fontsize=BIGGER_SIZE,\n",
    "            )\n",
    "                \n",
    "    axe.legend(loc='best', fontsize=10)\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e9770-5ef1-4c5d-8a4c-dd7cf354bbb4",
   "metadata": {},
   "source": [
    "Pour chaque jour d'expériences, on trace les différentes droites de calibration pour les standards avec ou sans plomb, et en mettant sur le même plot la droite du matin et celle du soir.\n",
    "On corrige la déviation des droites de calibration entre matin et soir par une régression linéaire en fonction de l'heure de mesure.\n",
    "Pour cela on fait la moyenne des durées d'acquisition des standards avec ou sans plomb pour obtenir $t1$ (matin) et $t2$ (soir)\n",
    "Puis on calcule $k(t) = \\frac{k2-k1}{t2-t1}$ avec $k1$ et $k2$ la pente extraite des droites de calibration le matin et le soir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10df746-ab2a-4363-9305-913ed2fdd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui sert à convertir la durée d'acquisition des standards en secondes \n",
    "def timestamp_total_seconds(ts):\n",
    "    return  ts.hour * 3600 + ts.minute * 60 + ts.second\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366a4dc-d0b8-4720-b4ef-3296314f3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fusionne les trois documents Rapport, PIGE et PIXE \n",
    "report_pige_pixe = report.join([pige_table,pixe_table])\n",
    "\n",
    "# On calcule le nombre de lignes dans la planche de plot (nombre de jours de manips)\n",
    "report_par_jour = report_pige_pixe.groupby(report[\"Time\"].dt.date)\n",
    "\n",
    "# On trace la planche pour les plots \n",
    "fig, axes = plt.subplots(nrows=len(report_par_jour), ncols=2, figsize=(30,30))\n",
    "\n",
    "# On convertit les valeurs de la colonne PbO en type non convertible et on affiche NaN si pas possible\n",
    "report_pige_pixe[\"PbO\"] = pd.to_numeric(report_pige_pixe[\"PbO\"], errors = \"coerce\")\n",
    "\n",
    "# On vérifie la longueur des dataframes\n",
    "print(\"Taille de report_pige_pixe:\", len(report_pige_pixe))\n",
    "\n",
    "sodium_conc_dfs = []\n",
    "\n",
    "# On fait une boucle for pour parcourir le rapport jour par jour et extraire les standards avec ou sans plomb\n",
    "for i, (day, group) in enumerate(report_par_jour):\n",
    "    time_sans_plomb = []\n",
    "    time_avec_plomb = []\n",
    "\n",
    "    # On sépare les standards avec ou sans plomb\n",
    "    stds_sans_plomb = group[group[\"Ref Objet\"].isin([\"BrillA\",\"BrillB\",\"BrillD\"])]\n",
    "    stds_avec_plomb = group[group[\"Ref Objet\"].isin([\"BrillC\",\"BG4\",\"BG3\"])]\n",
    "    \n",
    "    \n",
    "    # On sépare les standards avant et après midi\n",
    "    am_data_sans_plomb = stds_sans_plomb[stds_sans_plomb[\"Time\"].dt.hour < 12]\n",
    "    am_data_avec_plomb = stds_avec_plomb[stds_avec_plomb[\"Time\"].dt.hour < 12]\n",
    "\n",
    "    pm_data_sans_plomb = stds_sans_plomb[stds_sans_plomb[\"Time\"].dt.hour >= 12]\n",
    "    pm_data_avec_plomb = stds_avec_plomb[stds_avec_plomb[\"Time\"].dt.hour >= 12]\n",
    "    \n",
    "        \n",
    "    # On trace les droite de calibration et leur fit avec l'équation et le coefficient R\n",
    "    coefs_sans_plomb = calib(f\"Courbe de calibration Na PIGE sans Plomb {day}\", [am_data_sans_plomb, pm_data_sans_plomb], conc_stds_sans_plomb, axes[i, 0])\n",
    "    coefs_avec_plomb = calib(f\"Courbe de calibration Na PIGE avec Plomb {day}\", [am_data_avec_plomb, pm_data_avec_plomb], conc_stds_avec_plomb, axes[i, 1])\n",
    "\n",
    "    # On calcule la moyenne des temps de mesure des standards avec ou sans plomb, matin et soir\n",
    "    \n",
    "    t_moyen_sans_plomb_init = am_data_sans_plomb[\"Time\"].apply(timestamp_total_seconds).mean()                   \n",
    "    t_moyen_avec_plomb_init = am_data_avec_plomb[\"Time\"].apply(timestamp_total_seconds).mean()\n",
    "\n",
    "    t_moyen_sans_plomb_fin = pm_data_sans_plomb[\"Time\"].apply(timestamp_total_seconds).mean()                   \n",
    "    t_moyen_avec_plomb_fin = pm_data_avec_plomb[\"Time\"].apply(timestamp_total_seconds).mean()\n",
    "    \n",
    "   # on crée deux dataframe pour stocker les valeurs des temps moyens et des pentes calculées par calib, avec ou sans plomb\n",
    "    times_init =  pd.Series({\n",
    "        \"sans plomb\": t_moyen_sans_plomb_init, \n",
    "    })\n",
    "    coefs_init =  pd.Series({\n",
    "        \"sans plomb\": coefs_sans_plomb[0],\n",
    "    })       \n",
    "    times_fin = pd.Series({\n",
    "        \"sans plomb\": t_moyen_sans_plomb_fin, \n",
    "    })\n",
    "    coefs_fin = pd.Series({\n",
    "        \"sans plomb\": coefs_sans_plomb[-1],\n",
    "    })\n",
    "\n",
    "    if len(coefs_avec_plomb) == 2:\n",
    "        # cas ou on a une droite de calibration matin et soir pour standards avec plomb\n",
    "\n",
    "        # on rajoute les valeurs avec plomb matin et soir\n",
    "        times_init[\"avec plomb\"] = t_moyen_avec_plomb_init\n",
    "        coefs_init[\"avec plomb\"] = coefs_avec_plomb[0]\n",
    "        times_fin[\"avec plomb\"] = t_moyen_avec_plomb_fin\n",
    "        coefs_fin[\"avec plomb\"] = coefs_avec_plomb[-1]\n",
    "    \n",
    "    # Calcul du coefficient k de régression linéaire de correction d'heures\n",
    "    t_diff = times_fin - times_init\n",
    "    coefs_diff = coefs_fin - coefs_init\n",
    "\n",
    "    k = coefs_diff / t_diff\n",
    "    k_t_sans_plomb = k[\"sans plomb\"] * (group[\"Time\"].apply(timestamp_total_seconds) - times_fin[\"sans plomb\"]) + coefs_fin[\"sans plomb\"]\n",
    "    sodium_conc_day_df = pd.DataFrame({\n",
    "        \"Ref Objet\": group[\"Ref Objet\"],\n",
    "        \"PbO\": group[\"PbO\"], \n",
    "        \"Time\": group[\"Time\"],\n",
    "        \"A/D\": group[\"Aire Gaussien\"]/group[\"Dose\"],\n",
    "        \"k1\": coefs_init[\"sans plomb\"],\n",
    "        \"k2\": coefs_fin[\"sans plomb\"],\n",
    "        \"t1\": times_init[\"sans plomb\"],\n",
    "        \"t2\": times_fin[\"sans plomb\"],\n",
    "        \"k(t) sans plomb\": k_t_sans_plomb,\n",
    "    })\n",
    "\n",
    "    if len(coefs_avec_plomb) == 2:\n",
    "        k_t_avec_plomb = k[\"avec plomb\"] * (group[\"Time\"].apply(timestamp_total_seconds) - times_fin[\"avec plomb\"]) + coefs_fin[\"avec plomb\"]\n",
    "        sodium_conc_day_df[\"k(t) avec plomb\"] = k_t_avec_plomb\n",
    "        sodium_conc_day_df[\"Na2O PIGE\"] = np.where(\n",
    "            group[\"PbO\"] < 50000,\n",
    "            k_t_sans_plomb * group[\"A/D\"],\n",
    "            k_t_avec_plomb * group[\"A/D\"]\n",
    "        )\n",
    "    elif len(coefs_avec_plomb) == 1:\n",
    "        # cas ou on a une droite de calibration matin ou soir pour standards avec plomb, on prend la pente de la seule droite\n",
    "        sodium_conc_day_df[\"Na2O PIGE\"] = np.where(\n",
    "            group[\"PbO\"] < 50000,\n",
    "            k_t_sans_plomb * group[\"A/D\"],\n",
    "            coefs_avec_plomb[0] * group[\"A/D\"]\n",
    "        )\n",
    "    else:\n",
    "        # cas ou on a que des points (pas de droite) matin ou soir pour standards avec plomb\n",
    "        # on calcule le produit en croix avec la concentration et A/D de BG3 (standard avec la concentration en plomb la plus haute)\n",
    "        conc_bg3 = stds[stds[\"Ref Objet\"] == \"BG3\"][\"Conc theorique\"].item()\n",
    "        daily_ad_bg3 = group[group[\"Ref Objet\"] == \"BG3\"][\"A/D\"].item()\n",
    "        \n",
    "        sodium_conc_day_df[\"Na2O PIGE\"] = np.where(\n",
    "            group[\"PbO\"] < 50000,\n",
    "            k_t_sans_plomb * group[\"A/D\"],\n",
    "            conc_bg3 * group[\"A/D\"] / daily_ad_bg3\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "    sodium_conc_dfs.append(sodium_conc_day_df)\n",
    "\n",
    "sodium_conc_df = pd.concat(sodium_conc_dfs)\n",
    "sodium_conc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1043d673-7751-4cc5-af5c-2c2a70c88b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajouter pixe ref objet dans l'index\n",
    "pixe_table = pixe_table.set_index('Pixe Ref Objet', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a31cc-f74a-4d8c-a316-7416213fe9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'index est un tuple dans pixe_table donc on extrait que les valeurs de Na_conc_df\n",
    "pixe_table[\"Na2O PIGE\"] = sodium_conc_df[\"Na2O PIGE\"].values\n",
    "pixe_Na2O = pixe_table[\"Na2O\"]\n",
    "pixe_table = pixe_table.drop(columns=[\"Na2O\"])\n",
    "pige_corrected_compositions_table = pixe_table\n",
    "pige_corrected_compositions_table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a452e43-fd1b-46c6-908d-7f16531f23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97173e-ff6f-4892-9d55-7a886c5a81c6",
   "metadata": {},
   "source": [
    "# Normalisation du fichier PIXE PIGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2218615-21af-44e6-9085-34a55d805211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui permet de normaliser par rapport au Na2O PIGE\n",
    "\n",
    "def normalize(row: pd.Series):\n",
    "    cleaned_row = row.map(lambda s: pd.to_numeric(s, downcast=\"integer\", errors=\"coerce\"))\n",
    "    sodium_pige = cleaned_row.loc[\"Na2O PIGE\"]\n",
    "    total_comp_without_Na = 1000000 - sodium_pige\n",
    "    row_without_Na = cleaned_row.drop(\"Na2O PIGE\")\n",
    "    sum_comp_without_Na = row_without_Na.sum()\n",
    "    return pd.concat([pd.Series(sodium_pige, index=[\"Na2O PIGE\"]), row_without_Na.map(lambda x: x * total_comp_without_Na / sum_comp_without_Na)])\n",
    "\n",
    "normalized_compositions_table = pige_corrected_compositions_table.apply(normalize, axis=1)\n",
    "normalized_compositions_table.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4719e-2e44-4877-b672-2b239fcf0e10",
   "metadata": {},
   "source": [
    "# Test de la somme des lignes = 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368a3f0-dcbd-45bc-aa7a-1fb8b5c975b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_compositions_table.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96266a-7b7d-4063-bbc1-24e830d2c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_simplified_name(row, group_standards=True):\n",
    "    name = row[1].strip().replace(\" \", \"_\")\n",
    "    name = row[1].strip().replace(\"-\", \"_\")\n",
    "    \n",
    "    if \"_\" in name:\n",
    "        split = name.rsplit('_', 1)\n",
    "        return split[0] if \"pt\" in split[1] or \"map\" in split[1] else name\n",
    "    elif not group_standards and (stds[\"Ref Objet\"] == name).any():\n",
    "        return row[0]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "x_widget = widgets.FloatSlider(min=0.2, max=3.0, step=0.1)\n",
    "@interact(df=fixed(normalized_compositions_table), tolerance=x_widget, threshold=fixed(10000))\n",
    "def remove_outliers(df: pd.DataFrame, tolerance, threshold=10000):\n",
    "    \"\"\"\n",
    "    Supprime les valeurs aberrantes (outliers) d'un DataFrame basé sur des critères de tolérance et de seuil.\n",
    "\n",
    "    Cette fonction identifie les lignes du DataFrame `df` où les valeurs dépassent un certain seuil (`threshold`)\n",
    "    et calculent la déviation par rapport à la médiane au sein de chaque groupe simplifié.\n",
    "    Si la déviation relative dépasse la `tolerance`, la ligne est marquée pour suppression.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Le DataFrame contenant les données à analyser.\n",
    "        tolerance (float): Le seuil de tolérance pour déterminer si une valeur est un outlier. Les valeurs dont\n",
    "                           la déviation relative par rapport à la médiane dépasse cette tolérance seront considérées comme\n",
    "                           des outliers.\n",
    "        threshold (float, optional): Le seuil minimal que doit dépasser une valeur dans `normalized_compositions_table`\n",
    "                                     pour être prise en compte dans l'analyse. Par défaut à 10000.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste des indices des lignes du DataFrame `df` qui contiennent des valeurs aberrantes.\n",
    "        ```\n",
    "\n",
    "    \"\"\"\n",
    "    to_delete=[]\n",
    "    major_group = df[df > threshold].groupby(lambda x: extract_simplified_name(x, True), sort=False)\n",
    "    for name, grp in major_group:\n",
    "        # on évite les standards\n",
    "        if grp.count().max() <= 1 or (stds[\"Ref Objet\"] == name).any():\n",
    "            continue\n",
    "        \n",
    "        median = grp.median()\n",
    "        d = (grp - median) / median\n",
    "        for i, row in d.iterrows():\n",
    "            for j, elt in row[row > tolerance].items():\n",
    "                print(i, j)\n",
    "                to_delete.append(i)\n",
    "                \n",
    "    return to_delete\n",
    "\n",
    "#normalized_compositions_table.loc[to_delete[0]]\n",
    "#df_group.filter(detect_outliers)\n",
    "#pager(res,5,10)\n",
    "#pager(comp_table_without_outliners,90,10)\n",
    "#for idx in to_delete:\n",
    "#    print(idx[2])\n",
    "tolerance_final_w = widgets.FloatText(\n",
    "    value=0.5,\n",
    "    description='tolerance finale:',\n",
    "    disabled=False\n",
    ")\n",
    "display(tolerance_final_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12166e1-9179-494a-a83b-fe101b1243b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(remove_outliners(normalized_compositions_table, tolerance=3.0))\n",
    "table_without_outliers = normalized_compositions_table.drop(remove_outliers(normalized_compositions_table, tolerance=tolerance_final_w.value))\n",
    "table_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79bd472-189e-4b2b-8c60-22188b8e6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_ppm = table_without_outliers.groupby(lambda x: extract_simplified_name(x, False), sort=False).agg([\"mean\", \"std\"])\n",
    "final_table_ppm_without_sigma = table_without_outliers.groupby(lambda x: extract_simplified_name(x, False), sort=False).mean()\n",
    "final_table_ppm_without_sigma.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd14536-e540-404a-83fa-2ed063a464a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_elements_list = [\"Na2O PIGE\", \"MgO\", \"Al2O3\", \"SiO2\", \"P2O5\", \"SO3\", \"Cl\", \"K2O\", \"CaO\", \"TiO2\",\"V2O3\", \"Cr2O3\", \"MnO\", \"Fe2O3\", \"CoO\", \"NiO\", \"CuO\", \"ZnO\", \"As2O5\", \"SrO\", \"Ag2O\", \"SnO2\", \"Sb2O5\", \"BaO\", \"Au2O3\", \"PbO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4981623-3862-4eaf-8d01-a0127f396fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_ppm_major_elements = final_table_ppm[major_elements_list]\n",
    "final_table_ppm_major_elements.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f8348-54ba-4de5-80d4-64d2f3a40b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_wt = (final_table_ppm / 10000).round(3)\n",
    "final_table_wt_without_sigma = (final_table_ppm_without_sigma / 10000).round(4)\n",
    "final_table_wt_without_sigma.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecd297-33f9-4f2b-af23-726b48be1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_wt_major_elts = final_table_wt[major_elements_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd5d95-b825-4318-960d-4e51339b5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "d = datetime.today().strftime(\"%Y%m%d%H%M\")\n",
    "with pd.ExcelWriter(f\"{d}_emma_final.xlsx\") as writer:\n",
    "    final_table_ppm.map(lambda x: f\"{x:.0f}\").to_excel(writer, sheet_name=\"ppm all elements\")\n",
    "    final_table_ppm_major_elements.map(lambda x: f\"{x:.0f}\").to_excel(writer, sheet_name=\"ppm major elements\")\n",
    "    final_table_ppm_without_sigma.map(lambda x: f\"{x:.0f}\").to_excel(writer, sheet_name=\"ppm without sigma\")\n",
    "    final_table_wt.to_excel(writer, sheet_name=\"wt all elements\")\n",
    "    final_table_wt_major_elts.to_excel(writer, sheet_name=\"wt major elements\")\n",
    "    final_table_wt_without_sigma.to_excel(writer, sheet_name=\"wt without sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284c459-22cd-4e80-83f5-49913269845e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
